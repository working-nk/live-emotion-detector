{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('F:\\\\Projects\\\\Emotion Detection\\\\Raw_Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['emotion']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "i = 0\n",
    "for arr in df['pixels']:\n",
    "    num = []\n",
    "    cut = arr.split(' ')\n",
    "    for pix in cut:\n",
    "        num.append(float(pix))\n",
    "    train.append(np.array(num).reshape(48,48))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(train).reshape((-1,48,48,1))\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2125deffc50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train[1120],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:\\\\Projects\\\\Emotion Detection\\\\Prepared_Data/feed_cv2.pickle','wb') as f:\n",
    "    pickle.dump(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:\\\\Projects\\\\Emotion Detection\\\\Prepared_Data/label_cv2.pickle','wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 20, 20, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 396,839\n",
      "Trainable params: 396,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),input_shape=(48,48,1),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "    model.compile(metrics=['accuracy'],optimizer='adam',loss='categorical_crossentropy')\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19377 samples, validate on 2154 samples\n",
      "Epoch 1/20\n",
      "19377/19377 [==============================] - 10s 540us/step - loss: 1.7724 - accuracy: 0.2675 - val_loss: 1.6641 - val_accuracy: 0.3431\n",
      "Epoch 2/20\n",
      "19377/19377 [==============================] - 11s 585us/step - loss: 1.5612 - accuracy: 0.3825 - val_loss: 1.4269 - val_accuracy: 0.4327\n",
      "Epoch 3/20\n",
      "19377/19377 [==============================] - 10s 534us/step - loss: 1.4041 - accuracy: 0.4473 - val_loss: 1.3437 - val_accuracy: 0.4703\n",
      "Epoch 4/20\n",
      "19377/19377 [==============================] - 11s 557us/step - loss: 1.3151 - accuracy: 0.4888 - val_loss: 1.3045 - val_accuracy: 0.4935\n",
      "Epoch 5/20\n",
      "19377/19377 [==============================] - 11s 556us/step - loss: 1.2336 - accuracy: 0.5298 - val_loss: 1.2888 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "19377/19377 [==============================] - 11s 562us/step - loss: 1.1651 - accuracy: 0.5548 - val_loss: 1.2811 - val_accuracy: 0.5084\n",
      "Epoch 7/20\n",
      "19377/19377 [==============================] - 11s 569us/step - loss: 1.0923 - accuracy: 0.5795 - val_loss: 1.2927 - val_accuracy: 0.5037\n",
      "Epoch 8/20\n",
      "19377/19377 [==============================] - 11s 573us/step - loss: 1.0339 - accuracy: 0.6088 - val_loss: 1.3037 - val_accuracy: 0.5325\n",
      "Epoch 9/20\n",
      "19377/19377 [==============================] - 11s 579us/step - loss: 0.9627 - accuracy: 0.6309 - val_loss: 1.3132 - val_accuracy: 0.5167\n",
      "Epoch 10/20\n",
      "19377/19377 [==============================] - 11s 583us/step - loss: 0.9096 - accuracy: 0.6511 - val_loss: 1.3831 - val_accuracy: 0.5237\n",
      "Epoch 11/20\n",
      "19377/19377 [==============================] - 11s 580us/step - loss: 0.8480 - accuracy: 0.6748 - val_loss: 1.3924 - val_accuracy: 0.5381\n",
      "Epoch 12/20\n",
      "19377/19377 [==============================] - 11s 581us/step - loss: 0.8038 - accuracy: 0.6969 - val_loss: 1.4854 - val_accuracy: 0.5255\n",
      "Epoch 13/20\n",
      "19377/19377 [==============================] - 11s 586us/step - loss: 0.7604 - accuracy: 0.7050 - val_loss: 1.4786 - val_accuracy: 0.5288\n",
      "Epoch 14/20\n",
      "19377/19377 [==============================] - 11s 591us/step - loss: 0.7271 - accuracy: 0.7202 - val_loss: 1.5557 - val_accuracy: 0.5251\n",
      "Epoch 15/20\n",
      "19377/19377 [==============================] - 13s 655us/step - loss: 0.7023 - accuracy: 0.7271 - val_loss: 1.6144 - val_accuracy: 0.5269\n",
      "Epoch 16/20\n",
      "19377/19377 [==============================] - 12s 637us/step - loss: 0.6576 - accuracy: 0.7493 - val_loss: 1.6397 - val_accuracy: 0.5246\n",
      "Epoch 17/20\n",
      "19377/19377 [==============================] - 11s 588us/step - loss: 0.6379 - accuracy: 0.7537 - val_loss: 1.6525 - val_accuracy: 0.5214\n",
      "Epoch 18/20\n",
      "19377/19377 [==============================] - 11s 592us/step - loss: 0.6096 - accuracy: 0.7658 - val_loss: 1.7575 - val_accuracy: 0.5125\n",
      "Epoch 19/20\n",
      "19377/19377 [==============================] - 12s 603us/step - loss: 0.6058 - accuracy: 0.7682 - val_loss: 1.7800 - val_accuracy: 0.5241\n",
      "Epoch 20/20\n",
      "19377/19377 [==============================] - 14s 718us/step - loss: 0.5780 - accuracy: 0.7796 - val_loss: 1.8141 - val_accuracy: 0.5265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21168dc6b70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(x_train,y_train,epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=callbacks,\n",
    "          steps_per_epoch=len(X_train) / 32,\n",
    "          use_multiprocessing=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\\\Programming\\\\Python\\\\Neural Network\\\\Emotion Detection\\\\Model/FED-48x48x1-CNN_cv2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
